{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  8 12:32:13 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100-PCI...  On   | 00000000:17:00.0 Off |                    0 |\r\n",
      "| N/A   26C    P0    31W / 250W |      0MiB / 40960MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.device_count())\n",
    "# print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: ModelCheckpoint(save_last=True, monitor=None) is a redundant configuration. You can save the last checkpoint with ModelCheckpoint(save_top_k=None, monitor=None).\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "2023-05-08 12:32:20.062213: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 12:32:20.149288: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name            | Type        | Params\n",
      "------------------------------------------------\n",
      "0 | encoder         | Encoder     | 27.7 M\n",
      "1 | decoder         | Decoder     | 40.1 M\n",
      "2 | quantize        | QuantizeEMA | 0     \n",
      "3 | quant_conv      | Conv2d      | 65.8 K\n",
      "4 | post_quant_conv | Conv2d      | 65.8 K\n",
      "------------------------------------------------\n",
      "67.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.9 M    Total params\n",
      "/home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 8, 8) = 16384 dimensions.\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "dict_keys(['state', 'param_groups'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:145: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n",
      "/home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/tmd4/.conda/envs/viewformer2/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: RuntimeWarning: You are using LearningRateMonitor callback with models that have no learning rate schedulers. Please see documentation for `configure_optimizers` method.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "bash: line 11: 2213663 Killed                  viewformer-cli train codebook --dataset \"/scratch/network/tmd4/viewformer/datasets/feitrue\" --job-dir \"/scratch/network/tmd4/viewformer/models/fei-codebook-th\" --num-gpus 0 --batch-size 160 --n-embed 1024 --learning-rate 1.584e-3 --total-steps 201000 --num-val-workers 1 --num-workers 1 --resume-from-checkpoint \"/scratch/network/tmd4/viewformer/models/interiornet-codebook-th/model.ckpt\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Validation sanity check: 0it [00:00, ?it/s]\r",
      "Validation sanity check:  50%|█████     | 1/2 [00:37<00:37, 37.87s/it]\r",
      "Validation sanity check: 100%|██████████| 2/2 [01:11<00:00, 35.66s/it]\r",
      "                                                                      \r",
      "\r",
      "Training: 0it [00:00, ?it/s]\r",
      "Training:   0%|          | 0/23 [00:00<?, ?it/s]\r",
      "Epoch 100:   0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'viewformer-cli train codebook \\\\\\n    --dataset \"/scratch/network/tmd4/viewformer/datasets/feitrue\" \\\\\\n    --job-dir \"/scratch/network/tmd4/viewformer/models/fei-codebook-th\" \\\\\\n    --num-gpus 0 \\\\\\n    --batch-size 160 \\\\\\n    --n-embed 1024 \\\\\\n    --learning-rate 1.584e-3 \\\\\\n    --total-steps 201000 \\\\\\n    --num-val-workers 1 \\\\\\n    --num-workers 1 \\\\\\n    --resume-from-checkpoint \"/scratch/network/tmd4/viewformer/models/interiornet-codebook-th/model.ckpt\"\\n'' returned non-zero exit status 137.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mviewformer-cli train codebook \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --dataset \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/scratch/network/tmd4/viewformer/datasets/feitrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --job-dir \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/scratch/network/tmd4/viewformer/models/fei-codebook-th\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --num-gpus 0 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --batch-size 160 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --n-embed 1024 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --learning-rate 1.584e-3 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --total-steps 201000 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --num-val-workers 1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --num-workers 1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --resume-from-checkpoint \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/scratch/network/tmd4/viewformer/models/interiornet-codebook-th/model.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/viewformer2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/viewformer2/lib/python3.8/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/viewformer2/lib/python3.8/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'viewformer-cli train codebook \\\\\\n    --dataset \"/scratch/network/tmd4/viewformer/datasets/feitrue\" \\\\\\n    --job-dir \"/scratch/network/tmd4/viewformer/models/fei-codebook-th\" \\\\\\n    --num-gpus 0 \\\\\\n    --batch-size 160 \\\\\\n    --n-embed 1024 \\\\\\n    --learning-rate 1.584e-3 \\\\\\n    --total-steps 201000 \\\\\\n    --num-val-workers 1 \\\\\\n    --num-workers 1 \\\\\\n    --resume-from-checkpoint \"/scratch/network/tmd4/viewformer/models/interiornet-codebook-th/model.ckpt\"\\n'' returned non-zero exit status 137."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "viewformer-cli train codebook \\\n",
    "    --dataset \"/scratch/network/tmd4/viewformer/datasets/feitrue\" \\\n",
    "    --job-dir \"/scratch/network/tmd4/viewformer/models/fei-codebook-th\" \\\n",
    "    --num-gpus 0 \\\n",
    "    --batch-size 160 \\\n",
    "    --n-embed 1024 \\\n",
    "    --learning-rate 1.584e-3 \\\n",
    "    --total-steps 201000 \\\n",
    "    --num-val-workers 1 \\\n",
    "    --num-workers 1 \\\n",
    "    --resume-from-checkpoint \"/scratch/network/tmd4/viewformer/models/interiornet-codebook-th/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tmd4/.conda/envs/viewformer2/bin/viewformer-cli\", line 10, in <module>\n",
      "    from importlib.metadata import distribution\n",
      "  File \"/home/tmd4/.conda/envs/viewformer2/lib/python3.8/importlib/metadata.py\", line 16, in <module>\n",
      "    from configparser import ConfigParser\n",
      "  File \"/home/tmd4/.conda/envs/viewformer2/lib/python3.8/configparser.py\", line 141, in <module>\n",
      "    from collections.abc import MutableMapping\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1510, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1553, in _fill_cache\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "viewformer-cli train codebook \\\n",
    "    --job-dir \"/scratch/network/tmd4/viewformer/models/fei-codebook-th\" \\\n",
    "    --dataset \"/scratch/network/tmd4/viewformer/datasets/feitrue\" \\\n",
    "    --num-gpus 1 \\\n",
    "    --batch-size 160 \\\n",
    "    --n-embed 1024 \\\n",
    "    --learning-rate 1.584e-3 \\\n",
    "    --total-steps 201000 \\\n",
    "    --resume-from-checkpoint \"/scratch/network/tmd4/viewformer/models/interiornet-codebook-th/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
